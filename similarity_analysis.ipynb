{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
        "\n",
        "# Load Nike data\n",
        "df = pd.read_csv(\"NikeProductDescriptions.csv\")\n",
        "print(f\"Loaded dataset with {len(df)} rows.\")\n",
        "print(\"Columns found:\", df.columns.tolist())\n",
        "\n",
        "# Use the correct column: 'Product Description'\n",
        "descriptions = df[\"Product Description\"].dropna().astype(str).tolist()\n",
        "\n",
        "# Preprocessing: use spaCy to tokenize, lowercase, lemmatize, remove stopwords and punctuation\n",
        "def preprocess(text):\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [\n",
        "        token.lemma_ for token in doc\n",
        "        if not token.is_stop and not token.is_punct and token.is_alpha\n",
        "    ]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Clean all descriptions\n",
        "print(\"Preprocessing product descriptions with spaCy...\")\n",
        "descriptions_cleaned = []\n",
        "for desc in tqdm(descriptions):\n",
        "    cleaned = preprocess(desc)\n",
        "    descriptions_cleaned.append(cleaned)\n",
        "\n",
        "# TF-IDF\n",
        "print(\"Computing TF-IDF vectors...\")\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(descriptions_cleaned)\n",
        "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n",
        "\n",
        "# Cosine similarity\n",
        "print(\"Calculating cosine similarity...\")\n",
        "cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Jaccard similarity\n",
        "def jaccard_sim(text1, text2):\n",
        "    set1, set2 = set(text1.split()), set(text2.split())\n",
        "    intersection = len(set1 & set2)\n",
        "    union = len(set1 | set2)\n",
        "    return intersection / union if union != 0 else 0\n",
        "\n",
        "print(\"Calculating Jaccard similarities...\")\n",
        "jaccard_sim_matrix = []\n",
        "for i in tqdm(range(len(descriptions_cleaned))):\n",
        "    row = []\n",
        "    for j in range(len(descriptions_cleaned)):\n",
        "        sim = jaccard_sim(descriptions_cleaned[i], descriptions_cleaned[j])\n",
        "        row.append(sim)\n",
        "    jaccard_sim_matrix.append(row)\n",
        "\n",
        "# Show top 5 most similar products to the first one (Cosine)\n",
        "print(\"\\nTop 5 products most similar to the first one (Cosine similarity):\")\n",
        "first_cosine = cosine_sim_matrix[0]\n",
        "top_indices_cosine = first_cosine.argsort()[::-1][1:6]\n",
        "for idx in top_indices_cosine:\n",
        "    print(f\"Index {idx}: Cosine = {first_cosine[idx]:.3f}, Desc: {descriptions[idx][:60]}...\")\n",
        "\n",
        "# Show top 5 most similar products to the first one (Jaccard)\n",
        "print(\"\\nTop 5 products most similar to the first one (Jaccard similarity):\")\n",
        "first_jaccard = jaccard_sim_matrix[0]\n",
        "top_indices_jaccard = sorted(range(len(first_jaccard)), key=lambda i: first_jaccard[i], reverse=True)[1:6]\n",
        "for idx in top_indices_jaccard:\n",
        "    print(f\"Index {idx}: Jaccard = {first_jaccard[idx]:.3f}, Desc: {descriptions[idx][:60]}...\")\n",
        "\n",
        "# Optionally save results\n",
        "# pd.DataFrame(cosine_sim_matrix).to_csv(\"cosine_similarity.csv\", index=False)\n",
        "# pd.DataFrame(jaccard_sim_matrix).to_csv(\"jaccard_similarity.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "h_mU3AWegXk4",
        "outputId": "54337a20-3a5c-4d3a-e794-08f5fc1e17f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 400 rows.\n",
            "Columns found: ['Title', 'Subtitle', 'Product Description']\n",
            "Preprocessing product descriptions with spaCy...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:03<00:00, 130.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing TF-IDF vectors...\n",
            "TF-IDF matrix shape: (400, 1833)\n",
            "Calculating cosine similarity...\n",
            "Calculating Jaccard similarities...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:01<00:00, 260.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 products most similar to the first one (Cosine similarity):\n",
            "Index 159: Cosine = 0.259, Desc: You'll score major points in this legendary classic. Crossin...\n",
            "Index 14: Cosine = 0.206, Desc: The radiance lives on in the Nike Air Force 1 '07, the baske...\n",
            "Index 343: Cosine = 0.197, Desc: Created for the hardwood but taken to the streets, the '80s ...\n",
            "Index 164: Cosine = 0.159, Desc: The Air Jordan 1 Mid brings full-court style and premium com...\n",
            "Index 27: Cosine = 0.158, Desc: Have you ever had déjà shoe? Flash back to one of the first ...\n",
            "\n",
            "Top 5 products most similar to the first one (Jaccard similarity):\n",
            "Index 159: Jaccard = 0.200, Desc: You'll score major points in this legendary classic. Crossin...\n",
            "Index 14: Jaccard = 0.167, Desc: The radiance lives on in the Nike Air Force 1 '07, the baske...\n",
            "Index 31: Jaccard = 0.130, Desc: More than perhaps any other silhouette, the Air More Uptempo...\n",
            "Index 37: Jaccard = 0.130, Desc: Vintage details elevate an icon to bring you timeless style ...\n",
            "Index 23: Jaccard = 0.128, Desc: Flash back to '96 in the Air Penny 2. Bold and unmistakable,...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(cosine_sim_matrix).to_csv(\"cosine_similarity.csv\", index=False)\n",
        "pd.DataFrame(jaccard_sim_matrix).to_csv(\"jaccard_similarity.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "G7nmPLIBh4aw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nike Product Description Similarity Analysis\n",
        "\n",
        "- Filtered the dataset to keep product descriptions.\n",
        "- Cleaned the text: lowercased, removed stopwords/punctuation, lemmatized.\n",
        "- Built TF-IDF vectors and computed cosine similarities.\n",
        "- Calculated Jaccard similarities on cleaned text.\n",
        "- Identified top 5 most similar products for the first item using both metrics."
      ],
      "metadata": {
        "id": "X8_5nPBUjlPW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}